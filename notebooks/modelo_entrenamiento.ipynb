{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c313bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 890, number of negative: 81856\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1672\n",
      "[LightGBM] [Info] Number of data points in the train set: 82746, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010756 -> initscore=-4.521495\n",
      "[LightGBM] [Info] Start training from score -4.521495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nitropc\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo guardado en: model/artifacts\\rawg_lgbm_success.joblib\n",
      "âœ… MÃ©tricas guardadas en: model/artifacts\\metrics.json\n",
      "ðŸ“ˆ ROC-AUC: 0.9970816080387915\n",
      "âœ… Features usadas: ['metacritic', 'rating_top', 'added', 'reviews_text_count', 'suggestions_count', 'reddit_count', 'twitch_count', 'youtube_count', 'release_year', 'release_month', 'days_since_release']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "try:\n",
    "    # Opcional en local\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\".env\", override=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "ARTIFACT_DIR = \"model/artifacts\"\n",
    "MODEL_PATH = os.path.join(ARTIFACT_DIR, \"rawg_lgbm_success.joblib\")\n",
    "METRICS_PATH = os.path.join(ARTIFACT_DIR, \"metrics.json\")\n",
    "\n",
    "SUCCESS_DEFINITION = {\n",
    "    \"type\": \"quality_plus_traction\",\n",
    "    \"rule\": \"is_success = 1 if (rating >= 4.0 AND ratings_count >= 100) else 0\",\n",
    "    \"rating_threshold\": 4.0,\n",
    "    \"ratings_count_threshold\": 100\n",
    "}\n",
    "\n",
    "\n",
    "def get_engine():\n",
    "    db_user = os.getenv(\"DB_USER\")\n",
    "    db_pass = os.getenv(\"DB_PASSWORD\")\n",
    "    db_host = os.getenv(\"DB_HOST\")\n",
    "    db_port = os.getenv(\"DB_PORT\", \"5432\")\n",
    "    db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "    missing = [k for k, v in {\n",
    "        \"DB_USER\": db_user,\n",
    "        \"DB_PASSWORD\": db_pass,\n",
    "        \"DB_HOST\": db_host,\n",
    "        \"DB_NAME\": db_name\n",
    "    }.items() if not v]\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"Faltan variables de entorno: {', '.join(missing)}\")\n",
    "\n",
    "    return create_engine(\n",
    "        f\"postgresql+psycopg2://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "    engine = get_engine()\n",
    "\n",
    "    # Cargamos dataset desde la VIEW (ya trae target + features preparadas)\n",
    "    df = pd.read_sql(\"SELECT * FROM public.rawg_train_dataset;\", engine)\n",
    "\n",
    "    if \"is_success\" not in df.columns:\n",
    "        raise RuntimeError(\"La vista public.rawg_train_dataset no contiene la columna is_success\")\n",
    "\n",
    "    # Tipos\n",
    "    df[\"is_success\"] = df[\"is_success\"].astype(int)\n",
    "\n",
    "    # Columnas que NO van en features (leakage + identificadores)\n",
    "    drop_cols = [\"id\", \"slug\", \"name\", \"released\", \"updated\", \"is_success\", \"rating\", \"ratings_count\"]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "    # Asegurar que solo usamos numÃ©ricas (la VIEW ya intenta devolver numÃ©ricas)\n",
    "    X = df[feature_cols].copy()\n",
    "    for c in X.columns:\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "\n",
    "    y = df[\"is_success\"]\n",
    "\n",
    "    # Split estratificado\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Pipeline: imputaciÃ³n + modelo\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", LGBMClassifier(\n",
    "            n_estimators=800,\n",
    "            learning_rate=0.03,\n",
    "            num_leaves=31,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            objective=\"binary\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    report = classification_report(y_test, pred, digits=3, output_dict=True)\n",
    "    auc = float(roc_auc_score(y_test, prob))\n",
    "\n",
    "    # Guardar artefacto completo para FastAPI\n",
    "    joblib.dump(\n",
    "        {\n",
    "            \"pipeline\": pipe,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"threshold\": 0.5,\n",
    "            \"success_definition\": SUCCESS_DEFINITION\n",
    "        },\n",
    "        MODEL_PATH\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"rows\": int(df.shape[0]),\n",
    "        \"positive_rate\": float(y.mean()),\n",
    "        \"roc_auc\": auc,\n",
    "        \"classification_report\": report,\n",
    "        \"success_definition\": SUCCESS_DEFINITION,\n",
    "        \"feature_cols\": feature_cols\n",
    "    }\n",
    "\n",
    "    with open(METRICS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"âœ… Modelo guardado en:\", MODEL_PATH)\n",
    "    print(\"âœ… MÃ©tricas guardadas en:\", METRICS_PATH)\n",
    "    print(\"ðŸ“ˆ ROC-AUC:\", auc)\n",
    "    print(\"âœ… Features usadas:\", feature_cols)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
